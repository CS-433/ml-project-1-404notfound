{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Different Models\n",
    "\n",
    "$\\lambda=1$, $k=5$, $\\text{degree}=9$\n",
    "\n",
    "Using all feature engineering techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "from utils.helpers import *\n",
    "from utils.prediction import *\n",
    "from utils.preprocess import *\n",
    "from utils.cross_validation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = './data/train.csv'\n",
    "TEST_PATH = './data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0\n",
    "degree = 9\n",
    "learning_rate = 0.1\n",
    "max_iter = 2000\n",
    "k_fold = 5\n",
    "seed = 20221031\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_raw_tr, tx_raw_tr, ids_tr = load_csv_data(TRAIN_PATH)\n",
    "_, tx_raw_te, ids_te = load_csv_data(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 1)\n",
      "(250000, 30)\n",
      "(568238, 30)\n"
     ]
    }
   ],
   "source": [
    "y_tr = process_y(y_raw_tr)\n",
    "tx_tr = tx_raw_tr\n",
    "tx_te = tx_raw_te\n",
    "print(y_tr.shape)\n",
    "print(tx_tr.shape)\n",
    "print(tx_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_tr[:, [22, 29]] = tx_tr[:, [29, 22]]\n",
    "tx_te[:, [22, 29]] = tx_te[:, [29, 22]]\n",
    "tx_tr[tx_tr[:, 0] == -999, 0] = np.nan\n",
    "tx_te[tx_te[:, 0] == -999, 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = np.nanmedian(np.hstack((tx_tr[:, 0], tx_te[:, 0])))\n",
    "tx_tr[np.isnan(tx_tr[:, 0]), 0] = median\n",
    "tx_te[np.isnan(tx_te[:, 0]), 0] = median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 138.47 ,   51.655,   97.827, ...,    1.24 ,   -2.475,    2.   ],\n",
       "       [ 160.937,   68.768,  103.235, ..., -999.   , -999.   ,    1.   ],\n",
       "       [ 112.501,  162.172,  125.953, ..., -999.   , -999.   ,    1.   ],\n",
       "       ...,\n",
       "       [ 105.457,   60.526,   75.839, ..., -999.   , -999.   ,    1.   ],\n",
       "       [  94.951,   19.362,   68.812, ..., -999.   , -999.   ,    0.   ],\n",
       "       [ 112.501,   72.756,   70.831, ..., -999.   , -999.   ,    0.   ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 30)\n",
      "(50000, 30)\n",
      "(200000, 1)\n",
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "k_indices = build_k_indices(y_tr, k_fold, seed)\n",
    "tx_tr, tx_dev, y_tr, y_dev = cross_validation_dataset(y_tr, tx_tr, k_indices, k=k_fold-1)\n",
    "print(tx_tr.shape)\n",
    "print(tx_dev.shape)\n",
    "print(y_tr.shape)\n",
    "print(y_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split datasets to different jet nums\n",
    "# and remove columns with missing values for each jet num\n",
    "tx_train_list, y_tr_list = split_jet_num(tx_tr, y_tr)\n",
    "tx_dev_list, y_dev_list = split_jet_num(tx_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "means = []\n",
    "stds = []\n",
    "for i in range(3):\n",
    "    mean = np.mean(tx_train_list[i], axis=0)\n",
    "    std = np.std(tx_train_list[i], axis=0)\n",
    "    tx_train_list[i] = np.clip(tx_train_list[i], mean-2*std, mean+2*std)\n",
    "    tx_dev_list[i] = np.clip(tx_dev_list[i], mean-2*std, mean+2*std)\n",
    "    means.append(mean)\n",
    "    stds.append(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add polynomial features\n",
    "for i in range(3):\n",
    "    tx_train_list[i] = build_poly(tx_train_list[i], degree)\n",
    "    tx_dev_list[i] = build_poly(tx_dev_list[i], degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79917, 162) (19996, 162)\n",
      "(62257, 198) (15287, 198)\n",
      "(57826, 261) (14717, 261)\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(tx_train_list[i].shape, tx_dev_list[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxs = [0, 0, 0]\n",
    "mins = [0, 0, 0]\n",
    "for i in range(3):\n",
    "    tx_train_list[i], tx_dev_list[i], maxs[i], mins[i] = normalization(\n",
    "        tx_train_list[i],\n",
    "        tx_dev_list[i]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression_plot(y_tr, tx_tr, y_dev, tx_dev, lambda_):\n",
    "    \"\"\"Ridge regression using normal equations.\n",
    "    Args:\n",
    "        y: numpy array of shape (N, 1), N is the number of samples.\n",
    "        tx: numpy array of shape (N, D), D is the number of features.\n",
    "        lambda_: scalar.\n",
    "\n",
    "    Returns:\n",
    "        w: optimal weights, numpy array of shape(D, 1), D is the number of features.\n",
    "        loss: scalar\n",
    "    \"\"\"\n",
    "    N, D = tx_tr.shape\n",
    "    I = np.eye(D)\n",
    "    w = np.linalg.solve(tx_tr.T @ tx_tr + 2 * N * lambda_ * I, tx_tr.T @ y_tr).reshape(-1, 1)\n",
    "    train_loss = compute_mse(y_tr, tx_tr, w)\n",
    "    dev_loss = compute_mse(y_dev, tx_dev, w)\n",
    "\n",
    "    return w, train_loss, dev_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best lambda for PRI_JET_NUM = 0 is 0.\n",
      "The best lambda for PRI_JET_NUM = 1 is 0.\n",
      "The best lambda for PRI_JET_NUM = 2 is 0.\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "dev_losses = []\n",
    "ws = []\n",
    "y_tr_pred, y_tr_true = np.empty((0, 1)), np.empty((0, 1))\n",
    "y_dev_pred, y_dev_true = np.empty((0, 1)), np.empty((0, 1))\n",
    "\n",
    "for i in range(len(tx_train_list)):\n",
    "    train_losses = []\n",
    "    dev_losses = []\n",
    "    w_list = []\n",
    "    lambda_list = [0]\n",
    "\n",
    "    y_tr = y_tr_list[i]\n",
    "    tx_tr_fe = tx_train_list[i]\n",
    "    y_dev = y_dev_list[i]\n",
    "    tx_dev_fe = tx_dev_list[i]\n",
    "\n",
    "    for lambda_ in lambda_list:\n",
    "        w, train_loss, dev_loss = ridge_regression_plot(\n",
    "            y_tr, tx_tr_fe,\n",
    "            y_dev, tx_dev_fe,\n",
    "            lambda_,\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "        dev_losses.append(dev_loss)\n",
    "        w_list.append(w)\n",
    "\n",
    "    # cross_validation_visualization(lambda_list, train_losses, dev_losses, i)\n",
    "    index = np.argmin(dev_losses)\n",
    "    best_lambda = lambda_list[index]\n",
    "    best_w = w_list[index]\n",
    "    print(\"The best lambda for PRI_JET_NUM = {} is {}.\".format(i, best_lambda))\n",
    "\n",
    "    y_tr_pred = np.vstack((y_tr_pred, predict_linear(tx_tr_fe, best_w)))\n",
    "    y_dev_pred = np.vstack((y_dev_pred, predict_linear(tx_dev_fe, best_w)))\n",
    "    y_tr_true = np.vstack((y_tr_true, y_tr))\n",
    "    y_dev_true = np.vstack((y_dev_true, y_dev))\n",
    "    ws.append(best_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "0.8308 0.7798631790744467 0.7061198315188084 0.7411617127384541\n",
      "Validation\n",
      "0.82938 0.7735764267830776 0.7065791016770259 0.7385614906070913\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1_score = compute_metrics(y_tr_true, y_tr_pred)\n",
    "print(\"Training\")\n",
    "print(accuracy, precision, recall, f1_score)\n",
    "\n",
    "accuracy, precision, recall, f1_score = compute_metrics(y_dev_true, y_dev_pred)\n",
    "print(\"Validation\")\n",
    "print(accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best lambda for PRI_JET_NUM = 0 is 1e-08.\n",
      "The best lambda for PRI_JET_NUM = 1 is 1e-08.\n",
      "The best lambda for PRI_JET_NUM = 2 is 1e-08.\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "dev_losses = []\n",
    "ws = []\n",
    "y_tr_pred, y_tr_true = np.empty((0, 1)), np.empty((0, 1))\n",
    "y_dev_pred, y_dev_true = np.empty((0, 1)), np.empty((0, 1))\n",
    "\n",
    "for i in range(len(tx_train_list)):\n",
    "    train_losses = []\n",
    "    dev_losses = []\n",
    "    w_list = []\n",
    "    lambda_list = [1e-8]\n",
    "\n",
    "    y_tr = y_tr_list[i]\n",
    "    tx_tr_fe = tx_train_list[i]\n",
    "    y_dev = y_dev_list[i]\n",
    "    tx_dev_fe = tx_dev_list[i]\n",
    "\n",
    "    for lambda_ in lambda_list:\n",
    "        w, train_loss, dev_loss = ridge_regression_plot(\n",
    "            y_tr, tx_tr_fe,\n",
    "            y_dev, tx_dev_fe,\n",
    "            lambda_,\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "        dev_losses.append(dev_loss)\n",
    "        w_list.append(w)\n",
    "\n",
    "    # cross_validation_visualization(lambda_list, train_losses, dev_losses, i)\n",
    "    index = np.argmin(dev_losses)\n",
    "    best_lambda = lambda_list[index]\n",
    "    best_w = w_list[index]\n",
    "    print(\"The best lambda for PRI_JET_NUM = {} is {}.\".format(i, best_lambda))\n",
    "\n",
    "    y_tr_pred = np.vstack((y_tr_pred, predict_linear(tx_tr_fe, best_w)))\n",
    "    y_dev_pred = np.vstack((y_dev_pred, predict_linear(tx_dev_fe, best_w)))\n",
    "    y_tr_true = np.vstack((y_tr_true, y_tr))\n",
    "    y_dev_true = np.vstack((y_dev_true, y_dev))\n",
    "    ws.append(best_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "0.83079 0.7790923538760375 0.7073295148149767 0.741478618245153\n",
      "Validation\n",
      "0.83004 0.7738445781590065 0.7088659552011258 0.7399314481576692\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1_score = compute_metrics(y_tr_true, y_tr_pred)\n",
    "print(\"Training\")\n",
    "print(accuracy, precision, recall, f1_score)\n",
    "\n",
    "accuracy, precision, recall, f1_score = compute_metrics(y_dev_true, y_dev_pred)\n",
    "print(\"Validation\")\n",
    "print(accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error_sgd(y_tr, tx_tr, y_dev, tx_dev, initial_w, max_iters, gamma, batch_size=1):\n",
    "    \"\"\"Linear regression using stochastic gradient descent.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, 1)\n",
    "        tx: numpy array of shape=(N, D)\n",
    "        initial_w: numpy array of shape=(D, 1). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "        batch_size: default 1, a scalar denoting the batch size\n",
    "\n",
    "    Returns:\n",
    "        w: the last weight vector of shape (D, 1)\n",
    "        loss: the corresponding mse loss\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    w = initial_w\n",
    "    train_loss = compute_mse(y_tr, tx_tr, w)\n",
    "    ws = [initial_w]\n",
    "    train_losses = [train_loss]\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # implement stochastic gradient descent.\n",
    "        for y_batch, tx_batch in batch_iter(y_tr, tx_tr, batch_size=batch_size, num_batches=1):\n",
    "\n",
    "            # compute gradient\n",
    "            grad = linear_reg_gradient(y_batch, tx_batch, w)\n",
    "\n",
    "            # update w by gradient\n",
    "            w = w - gamma * grad\n",
    "\n",
    "            # compute loss\n",
    "            train_loss = compute_mse(y_tr, tx_tr, w)\n",
    "            dev_loss = compute_mse(y_dev, tx_dev, w)\n",
    "\n",
    "            # store w and loss\n",
    "            ws.append(w)\n",
    "            train_losses.append(train_loss)\n",
    "            dev_losses.append(dev_loss)\n",
    "\n",
    "    index = np.argmin(dev_losses)\n",
    "    return ws[index], train_losses[index], dev_losses[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fyy/Windlike_repo/ml-project-1-404notfound/implementations.py:74: RuntimeWarning: overflow encountered in matmul\n",
      "  loss = 1 / (2 * N) * e.T @ e\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "dev_losses = []\n",
    "ws = []\n",
    "y_tr_pred, y_tr_true = np.empty((0, 1)), np.empty((0, 1))\n",
    "y_dev_pred, y_dev_true = np.empty((0, 1)), np.empty((0, 1))\n",
    "\n",
    "for i in range(len(tx_train_list)):\n",
    "\n",
    "    y_tr = y_tr_list[i]\n",
    "    tx_tr_fe = tx_train_list[i]\n",
    "    y_dev = y_dev_list[i]\n",
    "    tx_dev_fe = tx_dev_list[i]\n",
    "    initial_w = np.random.rand(tx_tr_fe.shape[1], 1)\n",
    "\n",
    "    best_w, train_loss, dev_loss = mean_squared_error_sgd(\n",
    "        y_tr, tx_tr_fe,\n",
    "        y_dev, tx_dev_fe,\n",
    "        initial_w,\n",
    "        max_iter,\n",
    "        learning_rate,\n",
    "        batch_size=tx_tr_fe.shape[0]\n",
    "    )\n",
    "\n",
    "    y_tr_pred = np.vstack((y_tr_pred, predict_linear(tx_tr_fe, best_w)))\n",
    "    y_dev_pred = np.vstack((y_dev_pred, predict_linear(tx_dev_fe, best_w)))\n",
    "    y_tr_true = np.vstack((y_tr_true, y_tr))\n",
    "    y_dev_true = np.vstack((y_dev_true, y_dev))\n",
    "    ws.append(best_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "0.7357 0.7266031819097212 0.36809350997624357 0.4886429594087373\n",
      "Validation\n",
      "0.73474 0.7226071638285378 0.3607951213791486 0.4812859321835035\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1_score = compute_metrics(y_tr_true, y_tr_pred)\n",
    "print(\"Training\")\n",
    "print(accuracy, precision, recall, f1_score)\n",
    "\n",
    "accuracy, precision, recall, f1_score = compute_metrics(y_dev_true, y_dev_pred)\n",
    "print(\"Validation\")\n",
    "print(accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "dev_losses = []\n",
    "ws = []\n",
    "y_tr_pred, y_tr_true = np.empty((0, 1)), np.empty((0, 1))\n",
    "y_dev_pred, y_dev_true = np.empty((0, 1)), np.empty((0, 1))\n",
    "\n",
    "for i in range(len(tx_train_list)):\n",
    "\n",
    "    y_tr = y_tr_list[i]\n",
    "    tx_tr_fe = tx_train_list[i]\n",
    "    y_dev = y_dev_list[i]\n",
    "    tx_dev_fe = tx_dev_list[i]\n",
    "    initial_w = np.random.rand(tx_tr_fe.shape[1], 1)\n",
    "\n",
    "    best_w, train_loss, dev_loss = mean_squared_error_sgd(\n",
    "        y_tr, tx_tr_fe,\n",
    "        y_dev, tx_dev_fe,\n",
    "        initial_w,\n",
    "        max_iter,\n",
    "        learning_rate,\n",
    "        batch_size=1\n",
    "    )\n",
    "\n",
    "    y_tr_pred = np.vstack((y_tr_pred, predict_linear(tx_tr_fe, best_w)))\n",
    "    y_dev_pred = np.vstack((y_dev_pred, predict_linear(tx_dev_fe, best_w)))\n",
    "    y_tr_true = np.vstack((y_tr_true, y_tr))\n",
    "    y_dev_true = np.vstack((y_dev_true, y_dev))\n",
    "    ws.append(best_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "0.46158 0.30450619940157514 0.4434873857723755 0.3610850707835436\n",
      "Validation\n",
      "0.46172 0.3014178683638121 0.43878269027794065 0.3573543457497612\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1_score = compute_metrics(y_tr_true, y_tr_pred)\n",
    "print(\"Training\")\n",
    "print(accuracy, precision, recall, f1_score)\n",
    "\n",
    "accuracy, precision, recall, f1_score = compute_metrics(y_dev_true, y_dev_pred)\n",
    "print(\"Validation\")\n",
    "print(accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_logistic_regression_plot(y_tr, tx_tr, y_dev, tx_dev, lambda_, initial_w, max_iters, gamma, batch_size=8):\n",
    "    \"\"\"Regularized logistic regression using gradient descent\n",
    "    or SGD (y ∈ {0, 1}, with regularization term λ|w|2)\n",
    "\n",
    "    Args:\n",
    "        y_tr: numpy array of shape=(N_tr, 1)\n",
    "        tx_tr: numpy array of shape=(N_tr, D)\n",
    "        y_dev: numpy array of shape=(N_dev, 1)\n",
    "        tx_dev: numpy array of shape=(N_dev, D)\n",
    "        lambda_: a scalar denoting the regularization term\n",
    "        initial_w: numpy array of shape=(D, 1). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "        batch_size: mini batch size. default 8.\n",
    "        optimizer: 'gd' (batch sgd), 'ada' (adagrad), and 'adam'. default 'gd'.\n",
    "\n",
    "    Returns:\n",
    "        w: the best weight vector of shape (D, 1) for validation\n",
    "        train_loss: the corresponding mse loss\n",
    "        dev_loss: the corresponding mse loss\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    w = initial_w\n",
    "    ws = [initial_w]\n",
    "    train_losses = [compute_ce(y_tr, tx_tr, w)]\n",
    "    dev_losses = [compute_ce(y_dev, tx_dev, w)]\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        for y_batch, tx_batch in batch_iter(\n",
    "            y_tr, tx_tr, batch_size=batch_size, num_batches=1\n",
    "        ):\n",
    "            # compute gradient\n",
    "            grad = logistic_reg_gradient(y_batch, tx_batch, w)\n",
    "\n",
    "            # update w by gradient\n",
    "            w = w - gamma * (grad + 2 * lambda_ * w)\n",
    "\n",
    "            # compute loss\n",
    "            loss = compute_ce(y_tr, tx_tr, w)\n",
    "\n",
    "            # store w and loss\n",
    "            ws.append(w)\n",
    "            train_losses.append(loss)\n",
    "\n",
    "            # compute dev loss\n",
    "            dev_losses.append(compute_ce(y_dev, tx_dev, w))\n",
    "    \n",
    "    index = np.argmin(dev_losses)\n",
    "    return ws[index], train_losses[index], dev_losses[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best lambda for PRI_JET_NUM = 0 is 0.\n",
      "The best lambda for PRI_JET_NUM = 1 is 0.\n",
      "The best lambda for PRI_JET_NUM = 2 is 0.\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "dev_losses = []\n",
    "ws = []\n",
    "y_tr_pred, y_tr_true = np.empty((0, 1)), np.empty((0, 1))\n",
    "y_dev_pred, y_dev_true = np.empty((0, 1)), np.empty((0, 1))\n",
    "\n",
    "for i in range(len(tx_train_list)):\n",
    "    train_losses = []\n",
    "    dev_losses = []\n",
    "    w_list = []\n",
    "    lambda_list = [0]\n",
    "\n",
    "    y_tr = y_tr_list[i]\n",
    "    tx_tr_fe = tx_train_list[i]\n",
    "    y_dev = y_dev_list[i]\n",
    "    tx_dev_fe = tx_dev_list[i]\n",
    "\n",
    "    for lambda_ in lambda_list:\n",
    "        initial_w = np.random.rand(tx_tr_fe.shape[1], 1)\n",
    "        w, train_loss, dev_loss = reg_logistic_regression_plot(\n",
    "            y_tr, tx_tr_fe,\n",
    "            y_dev, tx_dev_fe,\n",
    "            lambda_,\n",
    "            initial_w,\n",
    "            max_iter,\n",
    "            learning_rate,\n",
    "            batch_size=tx_tr_fe.shape[0],\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "        dev_losses.append(dev_loss)\n",
    "        w_list.append(w)\n",
    "\n",
    "    index = np.argmin(dev_losses)\n",
    "    best_lambda = lambda_list[index]\n",
    "    best_w = w_list[index]\n",
    "    print(\"The best lambda for PRI_JET_NUM = {} is {}.\".format(i, best_lambda))\n",
    "\n",
    "    y_tr_pred = np.vstack((y_tr_pred, predict_logistic(tx_tr_fe, best_w)))\n",
    "    y_dev_pred = np.vstack((y_dev_pred, predict_logistic(tx_dev_fe, best_w)))\n",
    "    y_tr_true = np.vstack((y_tr_true, y_tr))\n",
    "    y_dev_true = np.vstack((y_dev_true, y_dev))\n",
    "    ws.append(best_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "0.80098 0.7423571969378312 0.6430559806450673 0.6891478195676621\n",
      "Validation\n",
      "0.8014 0.7382289994649546 0.6472381845901255 0.6897456726863713\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1_score = compute_metrics(y_tr_true, y_tr_pred)\n",
    "print(\"Training\")\n",
    "print(accuracy, precision, recall, f1_score)\n",
    "\n",
    "accuracy, precision, recall, f1_score = compute_metrics(y_dev_true, y_dev_pred)\n",
    "print(\"Validation\")\n",
    "print(accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best lambda for PRI_JET_NUM = 0 is 0.\n",
      "The best lambda for PRI_JET_NUM = 1 is 0.\n",
      "The best lambda for PRI_JET_NUM = 2 is 0.\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "dev_losses = []\n",
    "ws = []\n",
    "y_tr_pred, y_tr_true = np.empty((0, 1)), np.empty((0, 1))\n",
    "y_dev_pred, y_dev_true = np.empty((0, 1)), np.empty((0, 1))\n",
    "\n",
    "for i in range(len(tx_train_list)):\n",
    "    train_losses = []\n",
    "    dev_losses = []\n",
    "    w_list = []\n",
    "    lambda_list = [0]\n",
    "\n",
    "    y_tr = y_tr_list[i]\n",
    "    tx_tr_fe = tx_train_list[i]\n",
    "    y_dev = y_dev_list[i]\n",
    "    tx_dev_fe = tx_dev_list[i]\n",
    "\n",
    "    for lambda_ in lambda_list:\n",
    "        initial_w = np.random.rand(tx_tr_fe.shape[1], 1)\n",
    "        w, train_loss, dev_loss = reg_logistic_regression_plot(\n",
    "            y_tr, tx_tr_fe,\n",
    "            y_dev, tx_dev_fe,\n",
    "            lambda_,\n",
    "            initial_w,\n",
    "            max_iter,\n",
    "            learning_rate,\n",
    "            batch_size=1,\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "        dev_losses.append(dev_loss)\n",
    "        w_list.append(w)\n",
    "\n",
    "    index = np.argmin(dev_losses)\n",
    "    best_lambda = lambda_list[index]\n",
    "    best_w = w_list[index]\n",
    "    print(\"The best lambda for PRI_JET_NUM = {} is {}.\".format(i, best_lambda))\n",
    "\n",
    "    y_tr_pred = np.vstack((y_tr_pred, predict_logistic(tx_tr_fe, best_w)))\n",
    "    y_dev_pred = np.vstack((y_dev_pred, predict_logistic(tx_dev_fe, best_w)))\n",
    "    y_tr_true = np.vstack((y_tr_true, y_tr))\n",
    "    y_dev_true = np.vstack((y_dev_true, y_dev))\n",
    "    ws.append(best_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "0.78109 0.6982894925973839 0.6372261816273884 0.6663618490238216\n",
      "Validation\n",
      "0.78104 0.6950051098620337 0.6380321332238771 0.6653011311525527\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1_score = compute_metrics(y_tr_true, y_tr_pred)\n",
    "print(\"Training\")\n",
    "print(accuracy, precision, recall, f1_score)\n",
    "\n",
    "accuracy, precision, recall, f1_score = compute_metrics(y_dev_true, y_dev_pred)\n",
    "print(\"Validation\")\n",
    "print(accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalized Logistic Regression GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best lambda for PRI_JET_NUM = 0 is 1e-09.\n",
      "The best lambda for PRI_JET_NUM = 1 is 0.0001.\n",
      "The best lambda for PRI_JET_NUM = 2 is 1e-08.\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "dev_losses = []\n",
    "ws = []\n",
    "y_tr_pred, y_tr_true = np.empty((0, 1)), np.empty((0, 1))\n",
    "y_dev_pred, y_dev_true = np.empty((0, 1)), np.empty((0, 1))\n",
    "\n",
    "for i in range(len(tx_train_list)):\n",
    "    train_losses = []\n",
    "    dev_losses = []\n",
    "    w_list = []\n",
    "    lambda_list = np.logspace(-10, 1, 12)\n",
    "\n",
    "    y_tr = y_tr_list[i]\n",
    "    tx_tr_fe = tx_train_list[i]\n",
    "    y_dev = y_dev_list[i]\n",
    "    tx_dev_fe = tx_dev_list[i]\n",
    "\n",
    "    for lambda_ in lambda_list:\n",
    "        initial_w = np.random.rand(tx_tr_fe.shape[1], 1)\n",
    "        w, train_loss, dev_loss = reg_logistic_regression_plot(\n",
    "            y_tr, tx_tr_fe,\n",
    "            y_dev, tx_dev_fe,\n",
    "            lambda_,\n",
    "            initial_w,\n",
    "            max_iter,\n",
    "            learning_rate,\n",
    "            batch_size=tx_tr_fe.shape[0],\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "        dev_losses.append(dev_loss)\n",
    "        w_list.append(w)\n",
    "\n",
    "    index = np.argmin(dev_losses)\n",
    "    best_lambda = lambda_list[index]\n",
    "    best_w = w_list[index]\n",
    "    print(\"The best lambda for PRI_JET_NUM = {} is {}.\".format(i, best_lambda))\n",
    "\n",
    "    y_tr_pred = np.vstack((y_tr_pred, predict_logistic(tx_tr_fe, best_w)))\n",
    "    y_dev_pred = np.vstack((y_dev_pred, predict_logistic(tx_dev_fe, best_w)))\n",
    "    y_tr_true = np.vstack((y_tr_true, y_tr))\n",
    "    y_dev_true = np.vstack((y_dev_true, y_dev))\n",
    "    ws.append(best_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "0.801615 0.7432005379055303 0.6443822599215892 0.6902726712098858\n",
      "Validation\n",
      "0.8014 0.7394460876579726 0.6450099683358743 0.689007203257125\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1_score = compute_metrics(y_tr_true, y_tr_pred)\n",
    "print(\"Training\")\n",
    "print(accuracy, precision, recall, f1_score)\n",
    "\n",
    "accuracy, precision, recall, f1_score = compute_metrics(y_dev_true, y_dev_pred)\n",
    "print(\"Validation\")\n",
    "print(accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalized Logistic Regression SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best lambda for PRI_JET_NUM = 0 is 1e-09.\n",
      "The best lambda for PRI_JET_NUM = 1 is 1e-07.\n",
      "The best lambda for PRI_JET_NUM = 2 is 1e-07.\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "dev_losses = []\n",
    "ws = []\n",
    "y_tr_pred, y_tr_true = np.empty((0, 1)), np.empty((0, 1))\n",
    "y_dev_pred, y_dev_true = np.empty((0, 1)), np.empty((0, 1))\n",
    "\n",
    "for i in range(len(tx_train_list)):\n",
    "    train_losses = []\n",
    "    dev_losses = []\n",
    "    w_list = []\n",
    "    lambda_list = np.logspace(-10, 1, 12)\n",
    "\n",
    "    y_tr = y_tr_list[i]\n",
    "    tx_tr_fe = tx_train_list[i]\n",
    "    y_dev = y_dev_list[i]\n",
    "    tx_dev_fe = tx_dev_list[i]\n",
    "\n",
    "    for lambda_ in lambda_list:\n",
    "        initial_w = np.random.rand(tx_tr_fe.shape[1], 1)\n",
    "        w, train_loss, dev_loss = reg_logistic_regression_plot(\n",
    "            y_tr, tx_tr_fe,\n",
    "            y_dev, tx_dev_fe,\n",
    "            lambda_,\n",
    "            initial_w,\n",
    "            max_iter,\n",
    "            learning_rate,\n",
    "            batch_size=1,\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "        dev_losses.append(dev_loss)\n",
    "        w_list.append(w)\n",
    "\n",
    "    index = np.argmin(dev_losses)\n",
    "    best_lambda = lambda_list[index]\n",
    "    best_w = w_list[index]\n",
    "    print(\"The best lambda for PRI_JET_NUM = {} is {}.\".format(i, best_lambda))\n",
    "\n",
    "    y_tr_pred = np.vstack((y_tr_pred, predict_logistic(tx_tr_fe, best_w)))\n",
    "    y_dev_pred = np.vstack((y_dev_pred, predict_logistic(tx_dev_fe, best_w)))\n",
    "    y_tr_true = np.vstack((y_tr_true, y_tr))\n",
    "    y_dev_true = np.vstack((y_dev_true, y_dev))\n",
    "    ws.append(best_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "0.785035 0.7249183551638164 0.6017372801072683 0.6576090851895802\n",
      "Validation\n",
      "0.78552 0.7213596307175829 0.6047848012196552 0.6579484562388365\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1_score = compute_metrics(y_tr_true, y_tr_pred)\n",
    "print(\"Training\")\n",
    "print(accuracy, precision, recall, f1_score)\n",
    "\n",
    "accuracy, precision, recall, f1_score = compute_metrics(y_dev_true, y_dev_pred)\n",
    "print(\"Validation\")\n",
    "print(accuracy, precision, recall, f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "578317ea115a054ac4bccdfa892faa859649678dbaf6df54b2b98fb2846a81cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
